{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_kg_hide-output": true,
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"3\"\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models, optimizers, losses\n",
    "from tensorflow.keras.backend import ctc_batch_cost, ctc_decode\n",
    "from tensorflow.keras.utils import to_categorical, plot_model\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_dir = \"/kaggle/input/im2latex100k/formula_images_processed/formula_images_processed/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv(\"/kaggle/input/im2latex100k/im2latex_train.csv\", nrows=1000)\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = pd.read_csv(\"/kaggle/input/im2latex100k/im2latex_test.csv\", nrows=10)\n",
    "df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_valid = pd.read_csv(\"/kaggle/input/im2latex100k/im2latex_validate.csv\", nrows=10)\n",
    "df_valid.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train[\"image\"] = df_train[\"image\"].apply(lambda x: root_dir + x)\n",
    "df_test[\"image\"] = df_test[\"image\"].apply(lambda x: root_dir + x)\n",
    "df_valid[\"image\"] = df_valid[\"image\"].apply(lambda x: root_dir + x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train[\"image\"] = df_train[\"image\"].apply(lambda x: x if x.endswith(\".png\") else np.nan)\n",
    "df_test[\"image\"] = df_test[\"image\"].apply(lambda x: x if x.endswith(\".png\") else np.nan)\n",
    "df_valid[\"image\"] = df_valid[\"image\"].apply(lambda x: x if x.endswith(\".png\") else np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = df_train.dropna().reset_index(drop=True)\n",
    "df_valid = df_valid.dropna().reset_index(drop=True)\n",
    "df_test = df_test.dropna().reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_characters = set(char for formula in df_train['formula'] for char in formula)\n",
    "test_characters = set(char for formula in df_test['formula'] for char in formula)\n",
    "valid_characters = set(char for formula in df_valid['formula'] for char in formula)\n",
    "train_characters.update(test_characters)\n",
    "train_characters.update(valid_characters)\n",
    "characters = train_characters\n",
    "print(f\"Characters ({len(characters)}):\\n\", characters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "char_to_num = layers.StringLookup(\n",
    "    vocabulary = list(characters),\n",
    "    num_oov_indices = 0,\n",
    "    mask_token = None\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame({\"char\": char_to_num.get_vocabulary(),\n",
    "              \"num\": np.arange(1, len(char_to_num.get_vocabulary())+1)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_to_char = layers.StringLookup(\n",
    "    vocabulary = char_to_num.get_vocabulary(),\n",
    "    mask_token = None,\n",
    "    invert = True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = df_train['image'].values.tolist()\n",
    "y_train = df_train['formula'].values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_valid = df_valid['image'].values.tolist()\n",
    "y_valid = df_valid['formula'].values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = df_test['image'].values.tolist()\n",
    "y_test = df_test['formula'].values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(max([len(_) for _ in y_train]))\n",
    "print(max([len(_) for _ in y_test]))\n",
    "print(max([len(_) for _ in y_valid]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def encode_single_sample(image_path, label):\n",
    "    image = tf.io.read_file(image_path)\n",
    "    image = tf.io.decode_png(image, channels=1)\n",
    "    image = tf.image.convert_image_dtype(image, tf.float32)\n",
    "    image = tf.image.resize(image, [50, 200])\n",
    "    image = tf.transpose(image, perm=[1, 0, 2])\n",
    "    label = char_to_num(tf.strings.unicode_split(label, input_encoding=\"UTF-8\"))\n",
    "    label = tf.pad(label, paddings=[[0, 600 - tf.shape(label)[0]]], constant_values=0)\n",
    "    return {\"Input\": image, \"Label\": label}, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def process_dataset(X, y):\n",
    "    dataset = tf.data.Dataset.from_tensor_slices((X, y))\n",
    "    dataset = dataset.map(encode_single_sample, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
    "    dataset = dataset.batch(1024).prefetch(buffer_size=tf.data.experimental.AUTOTUNE)\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = process_dataset(X_train, y_train)\n",
    "valid_dataset = process_dataset(X_valid, y_valid)\n",
    "test_dataset = process_dataset(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_df(df: pd.DataFrame):\n",
    "    fig, axes = plt.subplots(4, 1, figsize=(10, 5))\n",
    "\n",
    "    for i, ax in enumerate(axes.ravel()):\n",
    "        if i < len(df):\n",
    "            a = np.random.randint(1, len(df), 1)[0]\n",
    "            img_path = df.loc[a][['image']].values[0]\n",
    "            label = df.loc[a][[\"formula\"]].values[0]\n",
    "            \n",
    "            image = Image.open(img_path).convert('RGB')\n",
    "            \n",
    "            ax.imshow(image)\n",
    "            ax.set_title(f\"LateX: {label}\")\n",
    "            ax.axis('off')\n",
    "            \n",
    "        else:\n",
    "            ax.axis('off')\n",
    "            \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_df(df_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CTCLayer(layers.Layer):\n",
    "    def __init__(self, name=None):\n",
    "        super().__init__(name=name)\n",
    "        self.loss_fn = ctc_batch_cost\n",
    "\n",
    "    def call(self, y_true, y_pred):\n",
    "        batch_length = tf.cast(tf.shape(y_true)[0], dtype=\"int64\")\n",
    "        input_length = tf.cast(tf.shape(y_pred)[1], dtype=\"int64\")\n",
    "        label_length = tf.cast(tf.shape(y_true)[1], dtype=\"int64\")\n",
    "\n",
    "        input_length = input_length * tf.ones(shape=(batch_length, 1), dtype=\"int64\")\n",
    "        label_length = label_length * tf.ones(shape=(batch_length, 1), dtype=\"int64\")\n",
    "\n",
    "        loss = self.loss_fn(y_true, y_pred, input_length, label_length)\n",
    "        self.add_loss(loss)\n",
    "\n",
    "        return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = (200, 50, 1)\n",
    "num_classes = len(characters) + 1  # +1 for the CTC blank label\n",
    "\n",
    "input_layer = layers.Input(shape=input_shape, name=\"Input\", dtype=\"float32\")\n",
    "label_layer = layers.Input(shape=(None,), name=\"Label\", dtype=\"float32\")\n",
    "\n",
    "conv2_1 = layers.Conv2D(filters=32, kernel_size=(3, 3), activation=\"relu\", kernel_initializer=\"he_normal\", padding=\"same\")(input_layer)\n",
    "max2_1 = layers.MaxPooling2D(pool_size=(2, 2))(conv2_1)\n",
    "\n",
    "conv2_2 = layers.Conv2D(filters=64, kernel_size=(3, 3), activation=\"relu\", kernel_initializer=\"he_normal\", padding=\"same\")(max2_1)\n",
    "max2_2 = layers.MaxPooling2D(pool_size=(2, 2))(conv2_2)\n",
    "\n",
    "reshape_shape = (input_shape[0] // 4, (input_shape[1] // 4) * 64)\n",
    "reshape_layer = layers.Reshape(target_shape=reshape_shape)(max2_2)\n",
    "\n",
    "dense_1 = layers.Dense(units=64, activation=\"relu\")(reshape_layer)\n",
    "drop_1 = layers.Dropout(0.2)(dense_1)\n",
    "\n",
    "bilstm_1 = layers.Bidirectional(layers.LSTM(128, return_sequences=True, dropout=0.25))(drop_1)\n",
    "bilstm_2 = layers.Bidirectional(layers.LSTM(64, return_sequences=True, dropout=0.25))(bilstm_1)\n",
    "\n",
    "output_layer = layers.Dense(num_classes, activation=\"softmax\", name=\"Output\")(bilstm_2)\n",
    "\n",
    "output = CTCLayer(name=\"ctc_loss\")(label_layer, output_layer)\n",
    "\n",
    "model = models.Model(inputs=[input_layer, label_layer], outputs=output, name=\"OCR\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=optimizers.Adam())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_model(model, show_layer_names=True, show_shapes=True, expand_nested=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stopping = EarlyStopping(monitor=\"val_loss\", patience=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(\n",
    "    train_dataset,\n",
    "    validation_data=valid_dataset,\n",
    "    epochs=100,\n",
    "    # callbacks=[early_stopping]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 1260949,
     "sourceId": 2109044,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30733,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
